WEBVTT

1
00:00:00.000 --> 00:00:05.200
欢迎大家回来 在我们继续讲稀疏建模前 

2
00:00:05.200 --> 00:00:10.153
我想顺便提一下压缩感知这个话题 

3
00:00:10.153 --> 00:00:16.344
压缩感知 用到了我们之前学过的某些概念 

4
00:00:16.344 --> 00:00:21.165
但其目标不在于模拟或表示一个信号 

5
00:00:21.165 --> 00:00:25.703
而是提出新的模式 

6
00:00:25.703 --> 00:00:30.590
或新的感知范例 让我来说明一下吧 

7
00:00:30.590 --> 00:00:37.168
与之前一样 我们有一个信号x   

8
00:00:37.168 --> 00:00:40.939
我们假设这个信号和之前见到过的一样 

9
00:00:40.939 --> 00:00:47.693
可以用一个字典乘以一个稀疏向量来表示 这就是我们想感知的信号 

10
00:00:47.693 --> 00:00:52.115
在压缩感知中 

11
00:00:52.115 --> 00:00:56.196
我们将其与一个行降维矩阵相乘 

12
00:00:56.196 --> 00:01:02.967
这样我们就得到一个N维信号   

13
00:01:02.967 --> 00:01:10.295
并且将其用字典乘稀疏向量来表示 但是我们不是要去感知N个点 

14
00:01:10.295 --> 00:01:17.993
而是要感知矩阵Q与x的积 而Q是一个胖矩阵 

15
00:01:17.993 --> 00:01:21.240
它有N列 

16
00:01:21.240 --> 00:01:27.175
但是行数少于N 我们需要感知的内容少了 这就是称其为压缩感知的原因 

17
00:01:27.175 --> 00:01:33.290
让我们把这写成公式 

18
00:01:33.290 --> 00:01:40.890
先前已经说过 Dα=x 

19
00:01:40.890 --> 00:01:46.777
两侧都乘以感知矩阵Q 

20
00:01:46.777 --> 00:01:54.697
Q乘D定义了一个新字典 即D~ 

21
00:01:54.697 --> 00:02:03.153
再乘α 得到的稀疏向量不是x 而是 x~ 

22
00:02:03.153 --> 00:02:08.826
新的感知向量比原有的要短 

23
00:02:08.826 --> 00:02:13.960
结果是我们只需要感知更少的点 

24
00:02:13.960 --> 00:02:19.523
我们的目标是 从被感知到的x~和已知的D中恢复数据 

25
00:02:19.523 --> 00:02:25.324
因为我们知道感知矩阵 故也能知道字典D 

26
00:02:25.324 --> 00:02:30.331
我们需要恢复出α 从数学上看 

27
00:02:30.331 --> 00:02:35.497
这跟稀疏建模非常像 利用已知信号和字典 

28
00:02:35.497 --> 00:02:41.065
来重建α 而压缩感知所做的 

29
00:02:41.065 --> 00:02:47.390
是解决这个基础性的问题 总的来说 

30
00:02:47.390 --> 00:02:51.116
这种思想是提供成功重建的条件 

31
00:02:51.116 --> 00:02:58.047
这些条件与感知矩阵Q   

32
00:02:58.047 --> 00:03:02.639
稀疏表征字典D 

33
00:03:02.639 --> 00:03:06.364
稀疏参数α 都有关 

34
00:03:06.364 --> 00:03:11.650
所以说 压缩感知提供了一个非常好的数学理论 

35
00:03:11.650 --> 00:03:15.822
和实现重建所需的条件 

36
00:03:15.822 --> 00:03:22.936
如果我们能从x~中恢复α 

37
00:03:22.936 --> 00:03:29.087
那我们也能由Dα得到原始信号x 

38
00:03:29.087 --> 00:03:35.648
与稀疏建模里很多有意思的数学内容一样 

39
00:03:35.648 --> 00:03:41.225
压缩感知里面也不少相关的数学知识让其可以实现 

40
00:03:41.225 --> 00:03:45.490
但是 分清这两者还是很重要的 

41
00:03:45.490 --> 00:03:51.340
我们讨论稀疏建模的时候是指信号模型 

42
00:03:51.340 --> 00:03:57.170
而压缩感知是设计新的感知协议 

43
00:03:57.170 --> 00:04:01.850
那么 对什么样的信号我们会设计一个新感知协议 

44
00:04:01.850 --> 00:04:07.647
大部分压缩感知都在为稀疏信号设计新的感知协议 

45
00:04:07.647 --> 00:04:13.521
也就是那些可以用稀疏字典来表征的信号 

46
00:04:13.521 --> 00:04:19.010
所以这两者使用了相同的工具 但是目的不同 

47
00:04:19.010 --> 00:04:24.498
压缩感知试图扩展Nyquist理论 

48
00:04:24.498 --> 00:04:30.836
Nyquist理论是一个经典的带限信号取样或感知的理论 

49
00:04:30.836 --> 00:04:36.657
压缩感知探究的是 

50
00:04:36.657 --> 00:04:40.948
稀疏信号的采样或感知理论是怎样的 

51
00:04:40.948 --> 00:04:47.300
这就是压缩感知与稀疏建模的关系 

52
00:04:47.300 --> 00:04:50.780
在这一小段有关压缩感知的内容后 

53
00:04:50.780 --> 00:04:56.706
我们可以用几周的时间来讲述压缩感知的相关知识 

54
00:04:56.706 --> 00:05:01.890
但这并不是这一周甚至不是这门课程的主要内容 

55
00:05:01.890 --> 00:05:07.667
下一节课我们将继续讨论稀疏建模领域的几个概念 

56
00:05:07.667 --> 00:05:09.296
到时候见 

57
00:05:09.296 --> 00:05:10.778
非常感谢