WEBVTT

1
00:00:00.000 --> 00:00:05.799
Hello and welcome back. 
In this video we're going to learn about 

2
00:00:05.799 --> 00:00:09.967
Roto Brush. 
Roto Brush is the video segmentation 

3
00:00:09.967 --> 00:00:16.047
algorithm inside After Effects. 
After Effects is the video processing 

4
00:00:16.047 --> 00:00:20.871
product from Adobe. 
And Roto Brush was released around April 

5
00:00:20.871 --> 00:00:26.661
2010 with a new version of After Effects 
that was released at that time. 

6
00:00:26.661 --> 00:00:31.808
And it was considered one of the 
highlights of that new release. 

7
00:00:31.808 --> 00:00:38.080
So I think it's very cool to learn about 
the basic concepts behind Roto Brush. 

8
00:00:38.080 --> 00:00:42.455
So let's dive right in. 
When we are doing video segmentation, and 

9
00:00:42.455 --> 00:00:46.766
in particular, if we're doing video 
segmentation for products that are going 

10
00:00:46.766 --> 00:00:51.755
to be used, for example in advertising or 
the movie industry, we need some very 

11
00:00:51.755 --> 00:00:58.110
basic characteristics that need to hold. 
We need very high accuracy. 

12
00:00:58.110 --> 00:01:02.660
We need to be able to segmentation at the 
pixel, or even sub pixel level. 

13
00:01:02.660 --> 00:01:07.401
As we saw, these are very challenging 
problems, so the user is going to have to 

14
00:01:07.401 --> 00:01:10.750
be in the loop. 
And we want to make sure, that the way 

15
00:01:10.750 --> 00:01:15.491
the user is involved in the process, is a 
very comfortable way for the user. 

16
00:01:15.491 --> 00:01:19.978
And, if the user is involved, this has to 
be done basically in real time. 

17
00:01:19.978 --> 00:01:24.971
You cannot request from the user to do 
something, then go home, come a few hours 

18
00:01:24.971 --> 00:01:29.080
later, and see what are the results. 
You need the user to interact. 

19
00:01:29.080 --> 00:01:35.276
In real time with a computer and those 
are basic characteristics that any one of 

20
00:01:35.276 --> 00:01:39.670
these type of systems needs to have, and 
certainly Roto Brush has. 

21
00:01:39.670 --> 00:01:45.986
Now we need high quality. 
So we will need to be able to segment the 

22
00:01:45.986 --> 00:01:51.815
videos with very, very high quality to 
get to the sub-pixel levels to be able to 

23
00:01:51.815 --> 00:01:55.676
do that and this is a video that we have 
seen before. 

24
00:01:55.676 --> 00:01:59.683
Now why is this so challenging? 
For a number of reasons. 

25
00:01:59.683 --> 00:02:04.710
Some of them we have seen, and some of 
them I want to go back to them. 

26
00:02:04.710 --> 00:02:08.189
So these are some of the challenges that 
we encounter. 

27
00:02:08.189 --> 00:02:13.279
And we encounter them in the video, we 
also encountered them also in the images. 

28
00:02:13.279 --> 00:02:17.403
And that's why I basically using stills 
here as well to you to describe. 

29
00:02:17.403 --> 00:02:21.398
What is overlapping color distribution? 
What do I mean by that? 

30
00:02:21.398 --> 00:02:26.013
We saw in the previous. 
Slide that I want to segment out these 

31
00:02:26.013 --> 00:02:27.700
two players. 
But look. 

32
00:02:27.700 --> 00:02:33.293
This player has a white shirt and also 
people in the audience have white shirts. 

33
00:02:33.293 --> 00:02:38.187
This player has a blue shirt, there's 
also blue here, there's blue here, 

34
00:02:38.187 --> 00:02:41.613
there's blue here. 
So basically there is a lot of 

35
00:02:41.613 --> 00:02:45.808
overlapping colors. 
We discussed that early on, it looks like 

36
00:02:45.808 --> 00:02:51.541
color enough and therefore edges are not 
going to be sufficient to do an accurate 

37
00:02:51.541 --> 00:02:55.335
segmentation. 
Here is another examples where edges are 

38
00:02:55.335 --> 00:02:59.909
not going to be sufficient. 
There is basically no boundaries here. 

39
00:02:59.909 --> 00:03:05.680
So how do we know to segment out the car 
if I don't really see where the car ends? 

40
00:03:05.680 --> 00:03:11.045
Additional challenges that appear, in 
particular in video is that they are 

41
00:03:11.045 --> 00:03:16.411
what's called topological changes. 
So look how they are and here separated 

42
00:03:16.411 --> 00:03:20.327
from the body. 
In one of the next frames it's actually 

43
00:03:20.327 --> 00:03:23.880
touching the body and this hole has been 
created. 

44
00:03:23.880 --> 00:03:29.309
So the actual shape, the global shape of 
the object of interest, is changing. 

45
00:03:29.309 --> 00:03:33.219
And once again, it's changing here. 
There is a new host. 

46
00:03:33.219 --> 00:03:37.562
So there's a lot of variability because 
of the articulation. 

47
00:03:37.562 --> 00:03:41.400
And that makes the problem really, really 
challenging. 

48
00:03:41.400 --> 00:03:46.653
So, 
what are the type of features that are in 

49
00:03:46.653 --> 00:03:53.506
Roto Brush and in the segmentation behind 
Roto Brush that basically we need to 

50
00:03:53.506 --> 00:03:57.483
have? 
But also features that we need to have in 

51
00:03:57.483 --> 00:04:02.221
many, many of this type of video 
segmentation approaches. 

52
00:04:02.221 --> 00:04:05.690
So, accuracy we already talked about 
that. 

53
00:04:05.690 --> 00:04:09.322
Robustness. 
Robustness also refers to the fact that 

54
00:04:09.322 --> 00:04:14.592
not only the image can be changing. 
But we actually might have a very, very 

55
00:04:14.592 --> 00:04:18.795
rich variety of data. 
And we want this algorithm to work as 

56
00:04:18.795 --> 00:04:23.923
good as possible for all of them. 
It might work better for ss, better for 

57
00:04:23.923 --> 00:04:27.484
some of them. 
Meaning the use of magnet to be less 

58
00:04:27.484 --> 00:04:30.831
involved. 
For some the use of magnet to be more 

59
00:04:30.831 --> 00:04:35.960
involved but we want this to be a really 
good algorithm for all of them. 

60
00:04:35.960 --> 00:04:41.132
So it has to be practical and this is 
related to the user intervation we want 

61
00:04:41.132 --> 00:04:46.580
to make sure that when the user gets 
involved things get better because of the 

62
00:04:46.580 --> 00:04:51.200
involvement of the user and don't get 
worse so we don't want the user to 

63
00:04:51.200 --> 00:04:56.234
basically say oh, I'm happy with 
everything but this and then the user go 

64
00:04:56.234 --> 00:05:01.509
goes and does something that basically 
destroys the part that he or she was 

65
00:05:01.509 --> 00:05:07.612
already happy with so it has to be a 
natural work flow and very easy and as we 

66
00:05:07.612 --> 00:05:13.251
say has to be very computational 
efficiency so you know we have about 30 

67
00:05:13.251 --> 00:05:19.122
frames a second in the NTSE American 
system our, our and similar you know 24 

68
00:05:19.122 --> 00:05:25.071
to 30 frames between the empty seat and 
polly systems and we don't want every 

69
00:05:25.071 --> 00:05:31.019
frame to take hours we just want every 
frame to be done really kind of in an 

70
00:05:31.019 --> 00:05:36.358
interactive comfortable time. 
So, the algorithm I'm going to describe 

71
00:05:36.358 --> 00:05:40.059
has four major steps, that we see them 
here. 

72
00:05:40.059 --> 00:05:45.580
First of all, we're going to do 
segmentation one frame to the next frame, 

73
00:05:45.580 --> 00:05:49.297
then we're going to propagate multiple 
frames ahead. 

74
00:05:49.297 --> 00:05:54.607
And then, we're going to show local 
correction and I'm going to basically 

75
00:05:54.607 --> 00:06:00.675
briefly mention about post-processing 
which is a concept that we are segmenting 

76
00:06:00.675 --> 00:06:05.378
videos, not just still images. 
And we're going to see many, many very 

77
00:06:05.378 --> 00:06:09.020
cool examples. 
So, let's start with the localized 

78
00:06:09.020 --> 00:06:12.661
classifiers. 
So, let me explain what do I mean by 

79
00:06:12.661 --> 00:06:17.197
localized classifiers. 
We're going to assume, that we start, 

80
00:06:17.197 --> 00:06:23.331
from the segmentation, of a given frame. 
This segmentation, was obtained either 

81
00:06:23.331 --> 00:06:29.624
minorly, remember we are talking about 
segmenting entire videos, so certainly we 

82
00:06:29.624 --> 00:06:35.598
can ask, once in a while the user, to 
manually do a segmentation, but we know, 

83
00:06:35.598 --> 00:06:41.812
that we don't actually need that, because 
we have learned many ways, to do, this 

84
00:06:41.812 --> 00:06:46.990
type of, stilement segmentation. 
So we start, from one segmentation. 

85
00:06:46.990 --> 00:06:50.724
And we want to propagate this 
segmentation to the next one. 

86
00:06:50.724 --> 00:06:53.410
That's going to be our first challenge 
here. 

87
00:06:53.410 --> 00:06:58.200
Now we are going to have what we call 
local classifiers. 

88
00:06:58.200 --> 00:07:04.125
So, we're going to put windows centered 
around the segmentation, around the 

89
00:07:04.125 --> 00:07:10.302
boundaries that we have just computed. 
From each one of these windows that 

90
00:07:10.302 --> 00:07:14.475
basically go all around. 
So, every one has a window. 

91
00:07:14.475 --> 00:07:19.733
Every pixel has a window. 
Or maybe we do every few pixels going 

92
00:07:19.733 --> 00:07:25.325
around the curve, with some overlapping, 
as we have illustrated here. 

93
00:07:25.325 --> 00:07:30.250
From every one of these, we have very 
important information. 

94
00:07:30.250 --> 00:07:33.490
So once again, this is just a local 
window. 

95
00:07:33.490 --> 00:07:39.587
Is here because we are in a frame that 
we're given the segmentation for that 

96
00:07:39.587 --> 00:07:45.764
frame so we're on frame T, we have the 
boundary and we have the inside and the 

97
00:07:45.764 --> 00:07:50.833
outside of the object. 
Now because we have that we have two very 

98
00:07:50.833 --> 00:07:57.365
important characteristics in that window. 
We have a shape prior, that we say okay, 

99
00:07:57.365 --> 00:08:03.180
we believe that the next frame will have 
a similar shape, remember frames, are 

100
00:08:03.180 --> 00:08:08.618
very, very fast, in time so things can 
not in a normal video change a lot, 

101
00:08:08.618 --> 00:08:12.771
between frames. 
So we have, a shape prior, we also have a 

102
00:08:12.771 --> 00:08:18.511
color model, so we know what type of 
colors to expect in the foreground, what 

103
00:08:18.511 --> 00:08:21.910
that type colors to expect in the 
background. 

104
00:08:21.910 --> 00:08:28.980
That's for every one of these windows. 
So let's see how we use that. 

105
00:08:28.980 --> 00:08:35.163
We are now in frame T, and we want to be 
able to segment out frame T+1. 

106
00:08:35.163 --> 00:08:42.074
This we have, as I say, is one of the 
frames we mark by hand or is one of the 

107
00:08:42.074 --> 00:08:48.712
previous frames, as we're going to see in 
the next slide when we progress. 

108
00:08:48.712 --> 00:08:55.805
And we have these windows all around, and 
I want now to segment out the player 

109
00:08:55.805 --> 00:08:59.889
here. 
The first thing we do is we basically 

110
00:08:59.889 --> 00:09:05.907
move these windows to the new frame. 
Now we can just move them with basically 

111
00:09:05.907 --> 00:09:13.332
no shifts and that wouldn't be too bad or 
we can move them following what's called 

112
00:09:13.332 --> 00:09:17.630
motion estimation. 
Do you remember, when we talked about 

113
00:09:17.630 --> 00:09:22.085
video compression? 
We talk that we go in a block and look 

114
00:09:22.085 --> 00:09:25.915
for the most similar block in the 
previous frame. 

115
00:09:25.915 --> 00:09:28.260
This what we are doing now. 
So, 

116
00:09:28.260 --> 00:09:33.777
for example, we could go into every 
region and see either backwards or 

117
00:09:33.777 --> 00:09:40.161
foreground or forward, we can see what's 
the closest box, what's the closest local 

118
00:09:40.161 --> 00:09:44.023
window. 
So we can start for example in this local 

119
00:09:44.023 --> 00:09:50.486
window, look around the regions here and 
then move it the place that we believe is 

120
00:09:50.486 --> 00:09:54.663
the closest one. 
We can do the mean squared error, the 

121
00:09:54.663 --> 00:09:59.331
absolute difference. 
The same type of approach that we did for 

122
00:09:59.331 --> 00:10:03.453
prediction when we were talking about 
video compression. 

123
00:10:03.453 --> 00:10:06.618
So for every window we have a new 
position. 

124
00:10:06.618 --> 00:10:12.138
Again, if you believe that there is no, 
too much motion in the image, you can 

125
00:10:12.138 --> 00:10:17.585
just copy them to the same position. 
So we either copy them or we use this 

126
00:10:17.585 --> 00:10:22.663
motion estimation to move them. 
So now we have the windows in the new 

127
00:10:22.663 --> 00:10:26.960
frame that we are about to segment. 
Now remember, 

128
00:10:26.960 --> 00:10:32.659
I'm going to just pick two windows. 
I'm going to pick a window in the current 

129
00:10:32.659 --> 00:10:38.439
frame and one in the future frame. 
This is the segmentation that we know. 

130
00:10:38.439 --> 00:10:44.218
This is where we need to put it. 
Now we're transferring the red curve, to 

131
00:10:44.218 --> 00:10:49.757
the blue, because we have moved, the 
basic, the block here, but we don't 

132
00:10:49.757 --> 00:10:55.216
believe in the blue curve yet. 
That's the one that we need to adjust. 

133
00:10:55.216 --> 00:10:59.313
Now, remember that for this, which we 
call the training. 

134
00:10:59.313 --> 00:11:02.589
Because it's something that we already 
have, 

135
00:11:02.589 --> 00:11:06.982
we have a shape prior and we also have 
color distributions. 

136
00:11:06.982 --> 00:11:12.567
So, we have, we say, more or less, this 
is what we believe should be the curve 

137
00:11:12.567 --> 00:11:15.726
here. 
And these are the distributions of colors 

138
00:11:15.726 --> 00:11:18.520
in the foreground. 
I'm in the background. 

139
00:11:18.520 --> 00:11:23.469
Now why do I write here GMM? 
This stands for Gaussian mixture models. 

140
00:11:23.469 --> 00:11:28.199
That's one way to approximate the 
distribution of foreground and 

141
00:11:28.199 --> 00:11:32.056
background. 
Just think once again about the histogram 

142
00:11:32.056 --> 00:11:35.986
distributions. 
Now instead of having the histograms we 

143
00:11:35.986 --> 00:11:40.352
want to approximate, approximate them by 
a parametric function. 

144
00:11:40.352 --> 00:11:45.227
And that's why we are using for Roto 
Brush Gaussian mixture models. 

145
00:11:45.227 --> 00:11:49.774
But it's not critical now. 
Just remember, you have a distribution of 

146
00:11:49.774 --> 00:11:53.919
colors for the back, foreground, a 
distribution of colors for the 

147
00:11:53.919 --> 00:11:56.703
background. 
For simplicity, just think about 

148
00:11:56.703 --> 00:11:59.681
histograms. 
Now that's what we're going to try to 

149
00:11:59.681 --> 00:12:05.035
combine. 
To basically find the exact position of 

150
00:12:05.035 --> 00:12:08.885
the blue curve. 
So once again the red move to the blue 

151
00:12:08.885 --> 00:12:12.022
but we want to be able to shift that 
around. 

152
00:12:12.022 --> 00:12:16.800
So, this is going to provide us some 
information of where should it be. 

153
00:12:16.800 --> 00:12:21.981
I'm not going to allow it to change 
completely, because I'm not expecting a 

154
00:12:21.981 --> 00:12:28.139
complete shape the formation from frame 
to frame. I'm also not expecting complete 

155
00:12:28.139 --> 00:12:32.296
changes in the color, in the pixel values 
in the image. 

156
00:12:32.296 --> 00:12:38.301
So this provides me a very good prior, 
about the colors for every pixel, inside 

157
00:12:38.301 --> 00:12:43.030
here, I can say, are you more probably 
foreground or background? 

158
00:12:43.030 --> 00:12:47.470
So we can get a picture like this, and 
the idea is to merge. 

159
00:12:47.470 --> 00:12:55.228
A shape prior and a color prior. 
how to merge them is going to be what we 

160
00:12:55.228 --> 00:13:01.061
are going to explain next. 
The important part here is that from what 

161
00:13:01.061 --> 00:13:07.095
we already know, we can get for every 
block, kind of a distribution of 

162
00:13:07.095 --> 00:13:13.916
probability of shape and probability of 
colors, merge them, and then we get the 

163
00:13:13.916 --> 00:13:19.599
probability of every pixel being either 
foreground or background. 

164
00:13:19.599 --> 00:13:26.158
That happens for every single one of 
these blocks that have moved from the 

165
00:13:26.158 --> 00:13:32.225
previous frame. 
And therefore, we put it back, we get 

166
00:13:32.225 --> 00:13:39.921
that for the entire image. 
And from that for example using graph 

167
00:13:39.921 --> 00:13:46.701
cards we can get a segmentation. 
And from this frame we will be able to go 

168
00:13:46.701 --> 00:13:52.106
to the next frame. 
Before that, I have to explain to you how 

169
00:13:52.106 --> 00:13:57.603
we do this merging. 
For the merging, we have to remember that 

170
00:13:57.603 --> 00:14:02.001
we have both colors and shape as 
indicated here. 

171
00:14:02.001 --> 00:14:07.040
So for every block, color, and shape, how 
we combine them. 

172
00:14:07.040 --> 00:14:13.500
The basic idea is what's written here. 
If you have colors that are well 

173
00:14:13.500 --> 00:14:17.503
separated, trust them. 
If not, trust the shape. 

174
00:14:17.503 --> 00:14:21.780
If you're ambivalent, trust both and 
merge them. 

175
00:14:21.780 --> 00:14:26.904
So, we have the color distributions here. 
From the previous frame. 

176
00:14:26.904 --> 00:14:31.421
We have information from the previous 
frame, a segmentation that we trust. 

177
00:14:31.421 --> 00:14:34.143
And we got the shape prior, the color 
priors. 

178
00:14:34.143 --> 00:14:38.846
If the color distributions are well 
separated, so you look at the histograms 

179
00:14:38.846 --> 00:14:43.362
for example, of every color or a 
distribution of all of them together, and 

180
00:14:43.362 --> 00:14:48.126
you see that their very well separated, 
and are multiple ways to measure that. 

181
00:14:48.126 --> 00:14:52.974
If there was separated. 
Trust the colors, trust the probability, 

182
00:14:52.974 --> 00:14:59.648
and use this shape prior very limited. 
So, the shape prior was somewhere here, 

183
00:14:59.648 --> 00:15:05.053
that was the curve, you say. 
I'm going to let you be, any place, at a 

184
00:15:05.053 --> 00:15:11.198
relatively large distance, from what your 
shed prior predicted, so you basically 

185
00:15:11.198 --> 00:15:17.187
can go on every pixel that has, certain 
distance, from the, prior, it's an allow 

186
00:15:17.187 --> 00:15:21.309
reach, and for the prior. 
So you get, these two type of 

187
00:15:21.309 --> 00:15:26.365
probabilities, you merge them, you get 
your, confidence map, all the 

188
00:15:26.365 --> 00:15:29.943
probability, that we saw in the previous 
slide. 

189
00:15:29.943 --> 00:15:36.441
That, if you have this, confidence. 
If you don't trust him to much basically 

190
00:15:36.441 --> 00:15:44.209
you have that the distributions are more 
overlapping, then what you do is disband 

191
00:15:44.209 --> 00:15:48.530
that had a prior shape, you make it a bit 
narrow. 

192
00:15:48.530 --> 00:15:55.119
You say basically I don't want a late the 
boundary in this particular block to go 

193
00:15:55.119 --> 00:16:00.905
very far from what I predicted, has to be 
more or less where I predicted. 

194
00:16:00.905 --> 00:16:07.415
And the less you trust the color, because 
of overlapping, the more narrow you make 

195
00:16:07.415 --> 00:16:11.309
those binds. 
So these are three examples from the 

196
00:16:11.309 --> 00:16:13.575
video. 
And these are real examples. 

197
00:16:13.575 --> 00:16:18.639
So this is the back of the player, where 
the colors were very well separated. 

198
00:16:18.639 --> 00:16:22.903
This is the, another region. 
There is not such a clear separation. 

199
00:16:22.903 --> 00:16:26.435
And look here, 
even the image tells us the separation 

200
00:16:26.435 --> 00:16:29.833
between foreground and background is not 
very good. 

201
00:16:29.833 --> 00:16:35.030
For all the cases we get, as we saw in 
the previous slide, both color and shape. 

202
00:16:35.030 --> 00:16:38.809
The difference is, 
once we're given the shape prior, 

203
00:16:38.809 --> 00:16:43.967
something like this will be here. 
Here will be something like this. 

204
00:16:43.967 --> 00:16:48.500
And here will be this. 
How much we let that shape prior to 

205
00:16:48.500 --> 00:16:51.940
impose the actual position of the new 
curve. 

206
00:16:51.940 --> 00:16:57.270
If we trust a lot the color, we basically 
expand that shape prior a lot. 

207
00:16:57.270 --> 00:17:02.676
And we say, be anywhere you want, because 
I know colors are going to help me. 

208
00:17:02.676 --> 00:17:07.030
We trust that it be less, we see that 
this is a bit narrow. 

209
00:17:07.030 --> 00:17:12.961
When the color distributions basically 
don't provide any information, the shape 

210
00:17:12.961 --> 00:17:18.367
prior comes to the rescue and say, I'm 
sorry, you cannot change too much. 

211
00:17:18.367 --> 00:17:23.581
So it's a very, very narrow band. 
This always comes from the product. 

212
00:17:23.581 --> 00:17:27.919
It comes always from the colors of the 
previous frame. 

213
00:17:27.919 --> 00:17:34.507
The actual shape of the confidence of the 
prior depends on the confidence we have 

214
00:17:34.507 --> 00:17:38.042
here. 
These two, we add them, we normalize, and 

215
00:17:38.042 --> 00:17:42.300
we wait, we get what we solve in the 
previous example. 

216
00:17:42.300 --> 00:17:45.535
Here for example there is no way to use 
colors. 

217
00:17:45.535 --> 00:17:51.181
They are too similar but the shape prior, 
because the previous frame was so nicely 

218
00:17:51.181 --> 00:17:56.550
segmented, help us to continue with the 
segmentation for the next frame and so 

219
00:17:56.550 --> 00:17:59.648
on. 
This is a very important concept where we 

220
00:17:59.648 --> 00:18:04.950
merge different types of information to 
obtain the segmentation that we want. 

221
00:18:04.950 --> 00:18:08.505
That just illustrate how important this 
is. 

222
00:18:08.505 --> 00:18:11.320
We have here one frame. 
Segmented. 

223
00:18:11.320 --> 00:18:17.250
We have the horse segmented off and we're 
going to, want to segment the next frame. 

224
00:18:17.250 --> 00:18:23.533
So first of all why this local. 
Remember, having this frame, we are 

225
00:18:23.533 --> 00:18:27.624
having blogs around it and we do 
everything local. 

226
00:18:27.624 --> 00:18:33.268
Because the other lab, they share 
information, but everything is local. 

227
00:18:33.268 --> 00:18:38.259
If we were not to do it, 
so if we were to consider one entire 

228
00:18:38.259 --> 00:18:42.676
frame as one blog. 
There is so much variability in the 

229
00:18:42.676 --> 00:18:47.094
colors, that the distribution basically 
makes nonsense. 

230
00:18:47.094 --> 00:18:50.530
And we won't be able to segment the 
horse. 

231
00:18:50.530 --> 00:18:56.592
If we use the local, this is what we are 
going to get all ready. 

232
00:18:56.592 --> 00:19:04.069
Much, much better using local color 
models, because we only care about what 

233
00:19:04.069 --> 00:19:08.830
is around each one of the pixels in the 
boundary. 

234
00:19:08.830 --> 00:19:13.775
Now there is still problems, with 
basically, as we see here. 

235
00:19:13.775 --> 00:19:17.698
The horse is white, 
the carriage is also white. 

236
00:19:17.698 --> 00:19:21.621
So certainly, the color there won't help 
a lot. 

237
00:19:21.621 --> 00:19:25.117
And we see that problem coming here, 
okay? 

238
00:19:25.117 --> 00:19:31.854
But, that's where the shape prior. 
This provides both colors and shape for 

239
00:19:31.854 --> 00:19:36.544
the next frame. 
And that's where it comes to the rescue. 

240
00:19:36.544 --> 00:19:43.395
And here, we see what we get when we 
combine both locality and shape and color 

241
00:19:43.395 --> 00:19:46.946
priors. 
We get very nice prior that as I said 

242
00:19:46.946 --> 00:19:51.879
before, with an algorithm like graft 
guides, immediately gets the nice 

243
00:19:51.879 --> 00:19:56.526
segmentation, and we propagate the 
segmentation to the next frame. 

244
00:19:56.526 --> 00:20:01.817
So both local and combining shape and 
color is very important to get this 

245
00:20:01.817 --> 00:20:06.178
accurate segmentations. 
We're going to see very soon that the 

246
00:20:06.178 --> 00:20:09.753
locality's important beyond what I just 
explained. 

247
00:20:09.753 --> 00:20:15.759
It's also important to help the user have 
a much more friendly interaction with the 

248
00:20:15.759 --> 00:20:19.490
images. 
So, this is how we actually go from one 

249
00:20:19.490 --> 00:20:25.204
frame right to the next frame, but we 
don't want to do just one frame. 

250
00:20:25.204 --> 00:20:30.120
We want to do multiple frames. 
How do we do that? 

251
00:20:30.120 --> 00:20:36.317
So the basic first idea that will come to 
our mind is, okay segment the first 

252
00:20:36.317 --> 00:20:41.308
frame, go to the next frame. 
Then, from the segmentation of this 

253
00:20:41.308 --> 00:20:46.539
frame, go to the next one. 
From the segmentation of this one, go to 

254
00:20:46.539 --> 00:20:50.886
the next one. 
And keep going as long as you can, as far 

255
00:20:50.886 --> 00:20:54.749
as you can. 
But this has one fundamental problem. 

256
00:20:54.749 --> 00:21:00.290
The fundamental problem is the following. 
This is a frame that we trusted. 

257
00:21:00.290 --> 00:21:03.860
We trusted it a lot. 
Maybe because we need the hand 

258
00:21:03.860 --> 00:21:07.430
sanitation, maybe because we work very 
hard on that. 

259
00:21:07.430 --> 00:21:13.064
Now, this is the result of the algorithm 
I just described, based on this. 

260
00:21:13.064 --> 00:21:18.063
This might not be perfect. 
If I propagate these to the next one, 

261
00:21:18.063 --> 00:21:24.173
then the errors I created here, propagate 
to the next one, which means that my 

262
00:21:24.173 --> 00:21:28.300
shape priors error propagate, my color 
distributions. 

263
00:21:28.300 --> 00:21:33.450
Also the estimations for this frame 
propagate if there are any errors. 

264
00:21:33.450 --> 00:21:39.820
One way to address that is to say, okay 
in order to stabilize the system why 

265
00:21:39.820 --> 00:21:44.150
don't we let the color priors also to 
influence here. 

266
00:21:44.150 --> 00:21:49.174
Why don't we let them keep moving? 
And also here and also here. 

267
00:21:49.174 --> 00:21:55.331
This is the friend that we trusted a lot. 
So let's just have it move forward. 

268
00:21:55.331 --> 00:22:01.246
Remember that we are working in blocks. 
So locally, we let it move forward. 

269
00:22:01.246 --> 00:22:07.890
And in that way, everybody will get also 
some of the information that we have from 

270
00:22:07.890 --> 00:22:12.670
the original frame. 
And from the original segmentation that 

271
00:22:12.670 --> 00:22:17.349
we so much trusted. 
And in this way, what we get is that our 

272
00:22:17.349 --> 00:22:22.530
segmentation has propagated not only one 
frame, but has propagated. 

273
00:22:22.530 --> 00:22:26.621
Multiple frames. 
So, once again the information that we 

274
00:22:26.621 --> 00:22:32.608
trust, and because we're working locally, 
it doesn't have to be that we trust it 

275
00:22:32.608 --> 00:22:35.838
globally. 
It only has to be that we trust it 

276
00:22:35.838 --> 00:22:38.897
locally. 
That information we can propagate 

277
00:22:38.897 --> 00:22:42.174
multiple frames to help stabilize the 
system. 

278
00:22:42.174 --> 00:22:47.562
We could actually iterate and use the 
current segmentation as the initial 

279
00:22:47.562 --> 00:22:51.932
condition or the priors for the next 
segmentation and so on. 

280
00:22:51.932 --> 00:22:55.136
That's an option in this type of 
frameworks. 

281
00:22:55.136 --> 00:22:59.360
But the critical part is to use 
information that we trust. 

282
00:22:59.360 --> 00:23:06.004
As many frames ahead as possible. 
Before I give you some cool examples, 

283
00:23:06.004 --> 00:23:09.923
there's a couple of additional things 
that we need to do. 

284
00:23:09.923 --> 00:23:14.324
One of them is, how are we going to let 
the user to repair mistakes? 

285
00:23:14.324 --> 00:23:17.763
No matter how great the algorithm that we 
develop, 

286
00:23:17.763 --> 00:23:21.063
video segmentation is a very, very tough 
problem. 

287
00:23:21.063 --> 00:23:24.983
In particular, if we are going to segment 
two hour movies. 

288
00:23:24.983 --> 00:23:28.810
So, we need to let the user do repairs in 
the algorithm. 

289
00:23:28.810 --> 00:23:34.159
Remember, when we trust a friend, we're 
really trusted, so we better make sure 

290
00:23:34.159 --> 00:23:38.100
that all the friends, all the way, are in 
very good shape. 

291
00:23:38.100 --> 00:23:42.726
So here is an example. 
We have this progression, and then we 

292
00:23:42.726 --> 00:23:47.823
realize that it was good, it was good, 
but here there is a mistake. 

293
00:23:47.823 --> 00:23:51.980
So how are we going to let the user 
repair that mistake? 

294
00:23:51.980 --> 00:23:57.293
Here is where once again the work on 
local blocks helps a lot. 

295
00:23:57.293 --> 00:24:02.435
So we basically want to do that. 
We want to go and repair it. 

296
00:24:02.435 --> 00:24:07.149
And there is many packages that will help 
us to repair. 

297
00:24:07.149 --> 00:24:10.748
Basically, I want to illustrate that 
again. 

298
00:24:10.748 --> 00:24:15.279
Here we have it. 
And now we repair it. 

299
00:24:15.279 --> 00:24:20.922
So we repair it inside many different 
packages, Photoshop, After Effects, you 

300
00:24:20.922 --> 00:24:25.713
can just go and move that curve. 
But of course, remember they were 

301
00:24:25.713 --> 00:24:29.179
propagation before, there was propagation 
before. 

302
00:24:29.179 --> 00:24:34.089
So that mistake that we had before 
propagated, propagated, propagated. 

303
00:24:34.089 --> 00:24:38.711
I want to now the correction I did, I 
want it to propagate as well. 

304
00:24:38.711 --> 00:24:44.055
I don't want to to propagate backwards, 
if I'm happy with what happen in the 

305
00:24:44.055 --> 00:24:46.943
past. 
I don't want my correction here to 

306
00:24:46.943 --> 00:24:51.060
influence what happened here because I'm 
happy with that. 

307
00:24:51.060 --> 00:24:56.328
So, here we have everything based on 
local blocks, local patches. 

308
00:24:56.328 --> 00:25:02.244
And that's great. 
We go and look at every block, or every 

309
00:25:02.244 --> 00:25:07.200
patch, that is effected by my recent 
repair. 

310
00:25:07.200 --> 00:25:13.638
And because we have this motion 
estimation that we did, we know where are 

311
00:25:13.638 --> 00:25:20.015
these blocks going in the next frames. 
We have their position in the future as 

312
00:25:20.015 --> 00:25:25.992
well and then we go and do repairs only 
in those blocks may be we can expand a 

313
00:25:25.992 --> 00:25:31.968
couple to the side to just make it more 
continuous repair but we certainly are 

314
00:25:31.968 --> 00:25:38.020
not got going to let the propagation of 
that correction go all the way far away 

315
00:25:38.020 --> 00:25:41.500
here. 
And that's how we get this local control. 

316
00:25:41.500 --> 00:25:46.786
So these blocks are helping us to get 
lock and features, and are also helping 

317
00:25:46.786 --> 00:25:51.867
us to do the interaction must faster. 
So look what's going to happen now with 

318
00:25:51.867 --> 00:25:55.399
this repairs. 
We just do them and here it is. 

319
00:25:55.399 --> 00:25:59.826
We have repaired them. 
Let me show that again to you. 

320
00:25:59.826 --> 00:26:04.168
We had a mistake, but we just repaired 
that mistake. 

321
00:26:04.168 --> 00:26:11.740
We let that repair propagate to the 
corresponding blocks in future frames. 

322
00:26:11.740 --> 00:26:18.976
And then we get everything repaired. 
And then we can continue with this frame, 

323
00:26:18.976 --> 00:26:24.628
segmenting forward frames. 
So, this is very cool, this is the third 

324
00:26:24.628 --> 00:26:28.515
step that basically is the local 
correction. 

325
00:26:28.515 --> 00:26:34.049
The final thing is, we have, so far done 
segmentation frame by frame. 

326
00:26:34.049 --> 00:26:38.227
This is a movie. 
We need the segmentation to be coherent, 

327
00:26:38.227 --> 00:26:43.151
consistent across frames. 
One way of doing that is basic to smooth 

328
00:26:43.151 --> 00:26:46.284
this out. 
We have these segments per frame. 

329
00:26:46.284 --> 00:26:52.029
We're going to smooth them out across 
time, regularize them to make them look 

330
00:26:52.029 --> 00:26:56.133
better and then when I basically show you 
what happens. 

331
00:26:56.133 --> 00:27:01.742
So you see here you might be able. 
To see that the boundaries are a bit 

332
00:27:01.742 --> 00:27:07.804
rough here, and are much nicer here. 
We basically take the segmentation of 

333
00:27:07.804 --> 00:27:13.700
multiple frames and we smooth them out 
together, to get from this rough. 

334
00:27:13.700 --> 00:27:20.845
Segmentation to much nicer, much smooth 
segmentation, that help us either to put 

335
00:27:20.845 --> 00:27:25.820
this object in other movies, or to do 
different effects. 

336
00:27:25.820 --> 00:27:30.600
So now, it's time to show, examples of 
this very cool technique. 

337
00:27:30.600 --> 00:27:34.845
This is an example that we have seen a 
number of times before. 

338
00:27:34.845 --> 00:27:39.023
So, here we have multiple examples. 
But I'm going to run them now. 

339
00:27:39.023 --> 00:27:42.926
We have segmented out here, the person. 
He looks very nice. 

340
00:27:42.926 --> 00:27:47.240
He has all the components. 
He has the repair, the smoothing, 

341
00:27:47.240 --> 00:27:49.980
everything, 
and looks really, really nice. 

342
00:27:51.100 --> 00:27:56.499
Here is an example that we have seen 
multiple times and we see it with the 

343
00:27:56.499 --> 00:27:59.738
particular case where we blur the 
background. 

344
00:27:59.738 --> 00:28:04.706
This is a special effect that we have 
seen in the past, in one of the 

345
00:28:04.706 --> 00:28:09.622
introductory videos before. 
We segmented out the players and then we 

346
00:28:09.622 --> 00:28:14.552
put them in a blurry background to 
enhance the players and call the 

347
00:28:14.552 --> 00:28:20.337
attention of the viewer to the players. 
Some addition and really nice examples 

348
00:28:20.337 --> 00:28:24.660
of, of special effects. 
Here we have the original one. 

349
00:28:24.660 --> 00:28:29.677
And there is a special filter. 
You can see the lady surfing that has 

350
00:28:29.677 --> 00:28:34.104
been filtered out. 
So we first have to segment this with all 

351
00:28:34.104 --> 00:28:40.006
the problems of splashes from the water, 
topological changes occurring as we see 

352
00:28:40.006 --> 00:28:43.105
here. 
Once we segment that out, we can make 

353
00:28:43.105 --> 00:28:47.680
very nice special effects, like here. 
Here we changed the light. 

354
00:28:47.680 --> 00:28:52.491
In the person, as you can see. 
We don't have to affect the back ground, 

355
00:28:52.491 --> 00:28:55.629
because we have segmented the foreground 
out. 

356
00:28:55.629 --> 00:28:59.255
And here is the compulsive that we have 
seen before. 

357
00:28:59.255 --> 00:29:04.020
Everything starts from segmenting this 
very tough image. 

358
00:29:04.020 --> 00:29:08.701
I want to keep giving you examples. 
I think this is quite cool. 

359
00:29:08.701 --> 00:29:14.363
This is another example where we 
basically segment out the player from the 

360
00:29:14.363 --> 00:29:17.836
background. 
Look how difficult this problem is. 

361
00:29:17.836 --> 00:29:22.914
The background is all blue and white. 
Or blue and gray like the player. 

362
00:29:22.914 --> 00:29:26.929
A lot of confusion, but we have shape, 
and that helps a lot. 

363
00:29:26.929 --> 00:29:32.398
And once we segment this player out, we 
can basically modify the background, for 

364
00:29:32.398 --> 00:29:37.244
example, significantly blurried. 
And this is also based on the just, the 

365
00:29:37.244 --> 00:29:42.089
concept that I just explained to you of 
segmenting the foreground out. 

366
00:29:42.089 --> 00:29:46.935
For this particular, there are some 
additions on not only mottling the 

367
00:29:46.935 --> 00:29:51.020
foreground colors. 
We can also model the background colors. 

368
00:29:51.020 --> 00:29:55.799
All what I explain now, is let's model 
the program, color and shape. 

369
00:29:55.799 --> 00:29:59.782
Why not to do all this some learning of 
the background? 

370
00:29:59.782 --> 00:30:04.199
You can do that and then you get 
improvement in your results. 

371
00:30:04.199 --> 00:30:09.992
But again, the concepts are very similar. 
And, I want to give you one more example. 

372
00:30:09.992 --> 00:30:15.351
So, here is an outer special effect, 
where we basically, take the actor here, 

373
00:30:15.351 --> 00:30:19.551
segment it out, and we can repeat it in 
multiple positions. 

374
00:30:19.551 --> 00:30:23.172
Again, the big challenge here is to 
segment it out. 

375
00:30:23.172 --> 00:30:29.028
Here, there is very good basic contrast 
between the actor, in particular with the 

376
00:30:29.028 --> 00:30:33.661
shirt and the background, so color would 
be very important here. 

377
00:30:33.661 --> 00:30:39.544
But also the shape the actor is moving, 
but it's not completely deforming, so the 

378
00:30:39.544 --> 00:30:44.602
shape prior is critical. 
So this gives us an idea of what's behind 

379
00:30:44.602 --> 00:30:50.560
one of the popular video segmentation 
techniques in particularly Roto Brush 

380
00:30:50.560 --> 00:30:54.480
which is incorporated inside Abobe's 
After Effect. 

381
00:30:54.480 --> 00:30:58.714
And we have seen it has many components. 
It uses shape. 

382
00:30:58.714 --> 00:31:02.869
It uses color. 
It uses localized structures, localized 

383
00:31:02.869 --> 00:31:06.397
learning. 
Both to be able to do more accurate 

384
00:31:06.397 --> 00:31:10.552
predictions. 
And also to make it more friendly to the 

385
00:31:10.552 --> 00:31:14.080
user when the user needs to make 
corrections. 

386
00:31:14.080 --> 00:31:20.242
All those concepts put together is what 
leads to this very, very high accuracy 

387
00:31:20.242 --> 00:31:23.560
and very user-friendly video 
segmentation. 

388
00:31:23.560 --> 00:31:26.944
Thank you very much. 
I hope you enjoyed this and I will see 

389
00:31:26.944 --> 00:31:28.780
you in the next video. 
Thank you. 