WEBVTT

1
00:00:00.000 --> 00:00:04.261
Let us just present some very 
interesting, very simple and very 

2
00:00:04.261 --> 00:00:08.184
interesting at the same time, properties 
of mean filtering, 

3
00:00:08.184 --> 00:00:12.600
basically local averaging. 
Let's go right ahead into that. 

4
00:00:12.600 --> 00:00:17.381
So you see here the title Averaging, 
Gaussian Filter, and Heat Flow and we're 

5
00:00:17.381 --> 00:00:21.596
going to explain all of them. 
But let's just start with something very 

6
00:00:21.596 --> 00:00:26.188
simple with a very simple exercise. 
Let's assume I give you three numbers, 

7
00:00:26.188 --> 00:00:28.880
1, 
2, 

8
00:00:28.880 --> 00:00:33.927
and 3. 
And I'm asking you the following 

9
00:00:33.927 --> 00:00:39.796
question. 
I'm asking you to find the number a, such 

10
00:00:39.796 --> 00:00:51.226
that (a - 1)^2 + (a. 
- 2)^2 + (a - 3)^2 is as small as 

11
00:00:51.226 --> 00:00:53.121
possible. 
Find that number. 

12
00:00:53.121 --> 00:00:58.952
And, I'm going to basically ask you, if 
you need to do a lot of computations, I'm 

13
00:00:58.952 --> 00:01:03.398
going to ask you to say, no, I don't know 
how to do these fast. 

14
00:01:03.398 --> 00:01:08.791
So, you're basically going to have the 
following options to say, no, I don't 

15
00:01:08.791 --> 00:01:14.622
know how to do that immediately or fast 
or yes, and then it's. So one is going to 

16
00:01:14.622 --> 00:01:18.207
be no, 
there is going to be yes if you know how 

17
00:01:18.207 --> 00:01:24.337
to do it very fast. Very fast, I mean in 
your head with basically no pencil, 

18
00:01:24.337 --> 00:01:27.140
nothing. You can say, yes 0, 
yes 2, 

19
00:01:30.860 --> 00:01:32.504
yes 4. 
Okay? 

20
00:01:32.504 --> 00:01:39.261
Let's see if you know the answer to that. 
Okay. 

21
00:01:39.261 --> 00:01:44.262
Let's explain. 
The answer is 2. 

22
00:01:44.262 --> 00:01:49.605
How do I know that? 
Because it's the average of these three 

23
00:01:49.605 --> 00:01:54.316
numbers. 
The smallest number that will minimize 

24
00:01:54.316 --> 00:02:02.699
this sum is the average of these numbers. 
This is a very interesting property that 

25
00:02:02.699 --> 00:02:10.366
in general reads as follows. if I give 
you a set of numbers which are, let's 

26
00:02:10.366 --> 00:02:18.442
call them ai, a sub i, and I'm asking you 
to find the number a, such that the sum 

27
00:02:18.442 --> 00:02:25.379
for every i of (a - ai)^2 is as small as 
possible. 

28
00:02:25.379 --> 00:02:35.837
The result of this is the average of a. 
So, the number I'm looking is the average 

29
00:02:35.837 --> 00:02:41.838
of all the numbers that I have. 
So you basically sum all the numbers and 

30
00:02:41.838 --> 00:02:45.923
divide by the total number of ai's that 
you have. 

31
00:02:45.923 --> 00:02:52.591
It's actually not very hard to prove that 
if you remember some of your calculus, 

32
00:02:52.591 --> 00:02:58.039
very early calculus. 
So you basically define this as a n and 

33
00:02:58.039 --> 00:03:02.109
you take the derivative of these, with 
respect to a. 

34
00:03:02.109 --> 00:03:07.376
You make that derivative equal to 0. 
You're going to find the result is 

35
00:03:07.376 --> 00:03:11.366
basically the average. 
So this is very interesting. 

36
00:03:11.366 --> 00:03:18.169
When we are taking in an image, 
let's say a 3 x 3 average and replacing 

37
00:03:18.169 --> 00:03:21.958
this by the average of all the nine 
numbers here. 

38
00:03:21.958 --> 00:03:27.912
What I'm actually doing is I'm replacing 
this pixel value by the number that 

39
00:03:27.912 --> 00:03:30.312
minimizes the square error. 
Okay? 

40
00:03:30.312 --> 00:03:35.304
So this is kind of the mean square error. 
Remember, we talk about that when we were 

41
00:03:35.304 --> 00:03:38.923
doing compression. 
A very simple operation, once again, that 

42
00:03:38.923 --> 00:03:44.041
you can prove just by taking derivatives. 
So, that's one interesting characteristic 

43
00:03:44.041 --> 00:03:47.433
of the mean. 
When we're doing image processing, we're 

44
00:03:47.433 --> 00:03:50.540
basically finding the value that replaces 
that. 

45
00:03:50.540 --> 00:03:55.695
This is going to be very interesting. 
We're going to see in a few videos ahead 

46
00:03:55.695 --> 00:03:59.000
that by replacing this way of measuring 
the error, 

47
00:03:59.000 --> 00:04:04.353
we can get other substitutions of this. 
So this is one of the properties that are 

48
00:04:04.353 --> 00:04:08.650
very interesting of averaging. 
Let's look at a different property. 

49
00:04:08.650 --> 00:04:14.323
So, once again remember that what we are 
doing is averaging in a window. 

50
00:04:14.323 --> 00:04:19.443
It can be 3 x 3, 5 x 5, 10 x 10. 
It's just a window. 

51
00:04:19.443 --> 00:04:23.207
So what we are actually doing here is 
convolution. 

52
00:04:23.207 --> 00:04:29.005
For those that have a bit of background 
in signal processing, that wouldn't be a 

53
00:04:29.005 --> 00:04:31.941
surprise. 
But I'm going to be basically explaining 

54
00:04:31.941 --> 00:04:36.910
at, kind of a slightly different 
operation for convolution. 

55
00:04:36.910 --> 00:04:46.182
So the basic idea is, what we are doing 
is we are taking our image x, y and we're 

56
00:04:46.182 --> 00:04:51.962
convolving it with a filter. 
And, let's just convolve it with what's 

57
00:04:51.962 --> 00:04:58.764
called a Gaussian filter. 
Just a Gaussian function that has average 

58
00:04:58.764 --> 00:05:04.820
0 and some variants. 
And, remember, a Gaussian function looks 

59
00:05:04.820 --> 00:05:06.767
something like this. 
Okay? 

60
00:05:06.767 --> 00:05:10.350
It's one of the most simple functions we 
know. 

61
00:05:10.350 --> 00:05:14.557
So that's a weighted average. 
So in, in a discrete fashion, 

62
00:05:14.557 --> 00:05:19.776
we would basically instead of just 
putting 1, 1, 1 every place, 

63
00:05:19.776 --> 00:05:24.995
we would basically replace by the weights 
provided by the Gaussian. 

64
00:05:24.995 --> 00:05:30.943
So that gives us another function which 
we are going to call x, y sigma, because 

65
00:05:30.943 --> 00:05:34.913
depends on the variants of the Gaussian, 
this function. 

66
00:05:34.913 --> 00:05:40.206
So we could actually take a regular 
average, but it's nicer, it's more 

67
00:05:40.206 --> 00:05:43.809
elegant if I explain this with a Gaussian 
filter. 

68
00:05:43.809 --> 00:05:48.146
So, while we are doing this, we are doing 
a weighted average. 

69
00:05:48.146 --> 00:05:52.483
We are replacing the pixel by a weighted 
average around it. 

70
00:05:52.483 --> 00:05:54.910
That's all what we are doing. 
Now, 

71
00:05:54.910 --> 00:06:00.013
this function is very interesting. 
Once again, it's x, y sigma because 

72
00:06:00.013 --> 00:06:05.946
depends on the variance of the Gaussian. 
So let's just write something interesting 

73
00:06:05.946 --> 00:06:09.323
here. 
You might remember what's called the heat 

74
00:06:09.323 --> 00:06:12.196
flow. 
If not, I'm going to t explain it to you. 

75
00:06:12.196 --> 00:06:15.859
I'm going to just write it down and 
explain it to you. 

76
00:06:15.859 --> 00:06:20.816
So we are going to write and I'm going to 
use the same notations on purpose. 

77
00:06:20.816 --> 00:06:25.666
So I'm going to write that the function 
f, is changing in time. 

78
00:06:25.666 --> 00:06:32.276
So, I'm going to write the derivative is 
changing in time according to what's 

79
00:06:32.276 --> 00:06:38.265
called the Laplacian of f, 
[SOUND] which is equal to the second 

80
00:06:38.265 --> 00:06:47.888
derivative of f with respect to x plus 
the second derivative of f with respect 

81
00:06:47.888 --> 00:06:51.624
to y. 
So the image is changing according to the 

82
00:06:51.624 --> 00:06:55.140
Laplacian. 
So I basically look at the change in the 

83
00:06:55.140 --> 00:06:58.655
x direction. 
I do the second derivative, look at the 

84
00:06:58.655 --> 00:07:03.135
change in the y direction. 
Second derivative, so, double the change, 

85
00:07:03.135 --> 00:07:07.685
and basically, this is the heat flow. 
And, if you remember some basic 

86
00:07:07.685 --> 00:07:12.027
properties of the heat flow, it basically 
talks about diffusion. 

87
00:07:12.027 --> 00:07:16.232
So you have heat in a room and the heat 
diffuses in the room. 

88
00:07:16.232 --> 00:07:19.471
If everything is isotropic, nothing can 
stop it. 

89
00:07:19.471 --> 00:07:25.435
It diffuses according to this equation. 
Now, why did I write this? 

90
00:07:25.435 --> 00:07:32.160
Because, the Gaussian filter actually 
satisfies this equation. 

91
00:07:32.160 --> 00:07:38.792
It's actually something very interesting 
and exactly actually depends on the time, 

92
00:07:38.792 --> 00:07:45.619
so the more you let this diffuse is 
equivalent to having a large sigma, a 

93
00:07:45.619 --> 00:07:48.350
larger variance. 
So once again, 

94
00:07:48.350 --> 00:07:55.007
the result of doing this local averaging 
with a Gaussian filtering is equivalent 

95
00:07:55.007 --> 00:08:01.090
to the result of taking the image, 
thinking like the pixel values, the gray 

96
00:08:01.090 --> 00:08:05.857
values are heat, 
and let it run according to the heat flow 

97
00:08:05.857 --> 00:08:10.050
which is these and those are equivalent 
operations. 

98
00:08:10.050 --> 00:08:15.264
So if I let it run for certain time, once 
again, the pixel values are heat. 

99
00:08:15.264 --> 00:08:20.914
It's running for certain time, that's 
equivalent to picking a certain variance 

100
00:08:20.914 --> 00:08:26.490
that depends exactly on the time and 
applying a Gaussian filter to the image. 

101
00:08:26.490 --> 00:08:32.285
So the pixel values are diffusing in the 
same way as the heat flow is diffusing 

102
00:08:32.285 --> 00:08:35.182
heat. 
Those two are basically equivalent 

103
00:08:35.182 --> 00:08:38.513
things. 
Once again, it's not very hard to prove 

104
00:08:38.513 --> 00:08:41.628
that. 
And if you want one other interesting 

105
00:08:41.628 --> 00:08:48.624
exercise replace f by this expression. 
So basically, take the derivatives, don't 

106
00:08:48.624 --> 00:08:53.727
do the derivatives according to T, do the 
derivatives according to sigma. 

107
00:08:53.727 --> 00:08:59.325
And here, do the derivatives according to 
x and to y, and you're going to find that 

108
00:08:59.325 --> 00:09:04.594
this satisfies this equation. 
And that's because of derivatives are 

109
00:09:04.594 --> 00:09:11.014
linear, so this is a linear operation. 
And if you're not very familiar to how to 

110
00:09:11.014 --> 00:09:17.355
do that, just consider that as an extra 
exercise for those that want to go a bit 

111
00:09:17.355 --> 00:09:20.922
deeper in the math for this particular 
video. 

112
00:09:20.922 --> 00:09:26.866
And now, why is this interesting is 
because as we are going to see in a few 

113
00:09:26.866 --> 00:09:32.733
weeks ahead. Somebody might ask, okay, 
now you just told me that local image 

114
00:09:32.733 --> 00:09:37.995
processing is related to heat flow. 
Maybe I can design a different equation 

115
00:09:37.995 --> 00:09:42.656
here that will do other interesting 
things into image processing and we're 

116
00:09:42.656 --> 00:09:47.070
going to see that that's possible. 
And again, that's going to be a big 

117
00:09:47.070 --> 00:09:51.342
mathematical more advance and is going to 
happen in a few weeks. 

118
00:09:51.342 --> 00:09:56.140
So we have seen a couple if interesting 
properties of this local average. 

119
00:09:56.140 --> 00:10:01.211
One is that is kind of computing the 
means, the value that minimizes the mean 

120
00:10:01.211 --> 00:10:05.154
square error in the region. 
And the second, that there is an 

121
00:10:05.154 --> 00:10:07.960
equivalence between pixel values and 
heat. 

122
00:10:07.960 --> 00:10:13.440
And what this local averaging is doing is 
diffusing the pixel values and that's why 

123
00:10:13.440 --> 00:10:17.450
also is blurring the image. 
If you remember, we saw that it's 

124
00:10:17.450 --> 00:10:22.528
blurring it, because it's diffusing them. 
And we know that, again, that happens 

125
00:10:22.528 --> 00:10:25.957
with heat. 
If you start with hot in one place and 

126
00:10:25.957 --> 00:10:30.258
cold in the other, 
the heat flow will diffuse the heat and 

127
00:10:30.258 --> 00:10:34.930
will become more uniform. 
Of course, if you wait for a long time, 

128
00:10:34.930 --> 00:10:38.494
which is equivalent to using a very large 
variance, 

129
00:10:38.494 --> 00:10:43.712
what we get is basically the mean value. 
So you are going to basically get the 

130
00:10:43.712 --> 00:10:48.211
average in the whole image. 
So once again, a couple of interesting 

131
00:10:48.211 --> 00:10:53.402
properties about the local averaging. 
Next, we're going to see a different type 

132
00:10:53.402 --> 00:10:58.108
of local operation that will actually 
help us not to blur the edges. 

133
00:10:58.108 --> 00:11:00.600
See you in the next video. 
Thank you. 