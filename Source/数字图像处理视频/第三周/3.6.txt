Let us just present some very 
interesting, very simple and very interesting at the same time, properties 
of mean filtering, basically local averaging. 
Let's go right ahead into that. So you see here the title Averaging, 
Gaussian Filter, and Heat Flow and we're going to explain all of them. 
But let's just start with something very simple with a very simple exercise. 
Let's assume I give you three numbers, 1, 
2, and 3. 
And I'm asking you the following question. 
I'm asking you to find the number a, such that (a - 1)^2 + (a. 
- 2)^2 + (a - 3)^2 is as small as possible. 
Find that number. And, I'm going to basically ask you, if 
you need to do a lot of computations, I'm going to ask you to say, no, I don't know 
how to do these fast. So, you're basically going to have the 
following options to say, no, I don't know how to do that immediately or fast 
or yes, and then it's. So one is going to be no, 
there is going to be yes if you know how to do it very fast. Very fast, I mean in 
your head with basically no pencil, nothing. You can say, yes 0, 
yes 2, yes 4. 
Okay? Let's see if you know the answer to that. 
Okay. Let's explain. 
The answer is 2. How do I know that? 
Because it's the average of these three numbers. 
The smallest number that will minimize this sum is the average of these numbers. 
This is a very interesting property that in general reads as follows. if I give 
you a set of numbers which are, let's call them ai, a sub i, and I'm asking you 
to find the number a, such that the sum for every i of (a - ai)^2 is as small as 
possible. The result of this is the average of a. 
So, the number I'm looking is the average of all the numbers that I have. 
So you basically sum all the numbers and divide by the total number of ai's that 
you have. It's actually not very hard to prove that 
if you remember some of your calculus, very early calculus. 
So you basically define this as a n and you take the derivative of these, with 
respect to a. You make that derivative equal to 0. 
You're going to find the result is basically the average. 
So this is very interesting. When we are taking in an image, 
let's say a 3 x 3 average and replacing this by the average of all the nine 
numbers here. What I'm actually doing is I'm replacing 
this pixel value by the number that minimizes the square error. 
Okay? So this is kind of the mean square error. 
Remember, we talk about that when we were doing compression. 
A very simple operation, once again, that you can prove just by taking derivatives. 
So, that's one interesting characteristic of the mean. 
When we're doing image processing, we're basically finding the value that replaces 
that. This is going to be very interesting. 
We're going to see in a few videos ahead that by replacing this way of measuring 
the error, we can get other substitutions of this. 
So this is one of the properties that are very interesting of averaging. 
Let's look at a different property. So, once again remember that what we are 
doing is averaging in a window. It can be 3 x 3, 5 x 5, 10 x 10. 
It's just a window. So what we are actually doing here is 
convolution. For those that have a bit of background 
in signal processing, that wouldn't be a surprise. 
But I'm going to be basically explaining at, kind of a slightly different 
operation for convolution. So the basic idea is, what we are doing 
is we are taking our image x, y and we're convolving it with a filter. 
And, let's just convolve it with what's called a Gaussian filter. 
Just a Gaussian function that has average 0 and some variants. 
And, remember, a Gaussian function looks something like this. 
Okay? It's one of the most simple functions we 
know. So that's a weighted average. 
So in, in a discrete fashion, we would basically instead of just 
putting 1, 1, 1 every place, we would basically replace by the weights 
provided by the Gaussian. So that gives us another function which 
we are going to call x, y sigma, because depends on the variants of the Gaussian, 
this function. So we could actually take a regular 
average, but it's nicer, it's more elegant if I explain this with a Gaussian 
filter. So, while we are doing this, we are doing 
a weighted average. We are replacing the pixel by a weighted 
average around it. That's all what we are doing. 
Now, this function is very interesting. 
Once again, it's x, y sigma because depends on the variance of the Gaussian. 
So let's just write something interesting here. 
You might remember what's called the heat flow. 
If not, I'm going to t explain it to you. I'm going to just write it down and 
explain it to you. So we are going to write and I'm going to 
use the same notations on purpose. So I'm going to write that the function 
f, is changing in time. So, I'm going to write the derivative is 
changing in time according to what's called the Laplacian of f, 
[SOUND] which is equal to the second derivative of f with respect to x plus 
the second derivative of f with respect to y. 
So the image is changing according to the Laplacian. 
So I basically look at the change in the x direction. 
I do the second derivative, look at the change in the y direction. 
Second derivative, so, double the change, and basically, this is the heat flow. 
And, if you remember some basic properties of the heat flow, it basically 
talks about diffusion. So you have heat in a room and the heat 
diffuses in the room. If everything is isotropic, nothing can 
stop it. It diffuses according to this equation. 
Now, why did I write this? Because, the Gaussian filter actually 
satisfies this equation. It's actually something very interesting 
and exactly actually depends on the time, so the more you let this diffuse is 
equivalent to having a large sigma, a larger variance. 
So once again, the result of doing this local averaging 
with a Gaussian filtering is equivalent to the result of taking the image, 
thinking like the pixel values, the gray values are heat, 
and let it run according to the heat flow which is these and those are equivalent 
operations. So if I let it run for certain time, once 
again, the pixel values are heat. It's running for certain time, that's 
equivalent to picking a certain variance that depends exactly on the time and 
applying a Gaussian filter to the image. So the pixel values are diffusing in the 
same way as the heat flow is diffusing heat. 
Those two are basically equivalent things. 
Once again, it's not very hard to prove that. 
And if you want one other interesting exercise replace f by this expression. 
So basically, take the derivatives, don't do the derivatives according to T, do the 
derivatives according to sigma. And here, do the derivatives according to 
x and to y, and you're going to find that this satisfies this equation. 
And that's because of derivatives are linear, so this is a linear operation. 
And if you're not very familiar to how to do that, just consider that as an extra 
exercise for those that want to go a bit deeper in the math for this particular 
video. And now, why is this interesting is 
because as we are going to see in a few weeks ahead. Somebody might ask, okay, 
now you just told me that local image processing is related to heat flow. 
Maybe I can design a different equation here that will do other interesting 
things into image processing and we're going to see that that's possible. 
And again, that's going to be a big mathematical more advance and is going to 
happen in a few weeks. So we have seen a couple if interesting 
properties of this local average. One is that is kind of computing the 
means, the value that minimizes the mean square error in the region. 
And the second, that there is an equivalence between pixel values and 
heat. And what this local averaging is doing is 
diffusing the pixel values and that's why also is blurring the image. 
If you remember, we saw that it's blurring it, because it's diffusing them. 
And we know that, again, that happens with heat. 
If you start with hot in one place and cold in the other, 
the heat flow will diffuse the heat and will become more uniform. 
Of course, if you wait for a long time, which is equivalent to using a very large 
variance, what we get is basically the mean value. 
So you are going to basically get the average in the whole image. 
So once again, a couple of interesting properties about the local averaging. 
Next, we're going to see a different type of local operation that will actually 
help us not to blur the edges. See you in the next video. 
Thank you.