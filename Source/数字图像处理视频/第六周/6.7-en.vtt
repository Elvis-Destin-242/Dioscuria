WEBVTT

1
00:00:00.000 --> 00:00:04.211
Hello, and welcome back. 
We are going to now give an example of 

2
00:00:04.211 --> 00:00:09.708
Calculus of variations used in image 
processing, and these are the techniques 

3
00:00:09.708 --> 00:00:15.061
we just saw in the previous video. 
Let's apply them to image processing now. 

4
00:00:15.061 --> 00:00:20.129
And we're going to do that with one of 
the most famous equations in image 

5
00:00:20.129 --> 00:00:24.841
processing, in the area of partial 
differential equations in image 

6
00:00:24.841 --> 00:00:27.982
processing, and that's Anisotropic 
Diffusion. 

7
00:00:27.982 --> 00:00:32.108
What is that? 
If you remember, when we discussed the 

8
00:00:32.108 --> 00:00:38.251
Gaussian filtering and averaging images, 
we talked that those are, were like 

9
00:00:38.251 --> 00:00:42.543
diffusion of the pixel values all across 
the image. 

10
00:00:42.543 --> 00:00:46.583
What was happening is that we obtained 
blurring. 

11
00:00:46.583 --> 00:00:52.189
Because if there were edges basically, we 
were averaging across edges. 

12
00:00:52.189 --> 00:00:59.013
We were letting the pixels' values across 
edges to be basically mixed up and that's 

13
00:00:59.013 --> 00:01:03.644
when we obtained blurry. 
And that was Isotropic Smoothing. 

14
00:01:03.644 --> 00:01:09.331
It was just going all around. 
It didn't matter if it had boundaries or 

15
00:01:09.331 --> 00:01:14.124
not boundaries. 
What Anisotropic Smoothing or Anisotropic 

16
00:01:14.124 --> 00:01:20.380
Diffusion is trying to do is going to try 
to average pixels value, pixel values, 

17
00:01:20.380 --> 00:01:26.511
only on the right side of the object, 
on the right side of the edge, on the 

18
00:01:26.511 --> 00:01:30.737
correct object. 
So, pixel values here are going to be 

19
00:01:30.737 --> 00:01:36.206
averaged among themselves, to basically 
denoise or enhance the image. 

20
00:01:36.206 --> 00:01:41.344
Pixel values here are going to be 
basically mixed among themselves. 

21
00:01:41.344 --> 00:01:44.990
How do we do that? 
We do that with equations, 

22
00:01:44.990 --> 00:01:50.684
partial differential equations as we see 
here. Before we look at the equations, 

23
00:01:50.684 --> 00:01:54.480
let us look at the images, this is an 
original image. 

24
00:01:54.480 --> 00:02:00.570
And if we do basically, Gaussian 
Smoothing or Averaging, we know that we 

25
00:02:00.570 --> 00:02:04.909
are going to blur. 
We blur across the boundaries because 

26
00:02:04.909 --> 00:02:10.720
it's just mixing pixels from different 
objects and that's what we see here. 

27
00:02:10.720 --> 00:02:17.023
On the other hand, if we try not to blur, 
try not to mix, we only mix pixels on the 

28
00:02:17.023 --> 00:02:23.248
same side of the boundary without going 
in this direction, then we get the much 

29
00:02:23.248 --> 00:02:26.983
sharper. 
We still see that we have removed noise 

30
00:02:26.983 --> 00:02:33.364
inside the object, inside the grey matter 
of these MRI picture of the brain, we see 

31
00:02:33.364 --> 00:02:39.356
that this is much smoother, that we are 
still preserving the boundaries very, 

32
00:02:39.356 --> 00:02:43.625
very, nicely. 
The difference between these two is here, 

33
00:02:43.625 --> 00:02:50.133
we have what we have marked here with red 
background, is isotropic diffusion, heat 

34
00:02:50.133 --> 00:02:54.201
equation. 
We actually already talked about it that 

35
00:02:54.201 --> 00:02:59.733
we're going to to derive it in the next 
slide using Calculus of variations. 

36
00:02:59.733 --> 00:03:05.997
Here, we have added isotropic before we 
take the second derivative which is a 

37
00:03:05.997 --> 00:03:10.146
divergence. 
I have to basically remind you that the 

38
00:03:10.146 --> 00:03:17.860
Laplacian of the image is the divergence 
of the gradient. 

39
00:03:17.860 --> 00:03:24.316
And we are ready to define gradient and 
the divergence in the previous slides. 

40
00:03:24.316 --> 00:03:30.724
So, before we take it as here, 
we introduce a function in between here. 

41
00:03:30.724 --> 00:03:35.246
This is a very similar function as the 
one that we used for active counters. 

42
00:03:35.246 --> 00:03:39.829
It's, for example, one over the gradient, 
we are going to see that in the next 

43
00:03:39.829 --> 00:03:42.000
slide. 
So, a function is going to say, 

44
00:03:42.000 --> 00:03:45.330
wait a second. 
Don't diffuse if there is a strong 

45
00:03:45.330 --> 00:03:47.233
gradient. 
Stop the diffusion. 

46
00:03:47.233 --> 00:03:52.398
And that's why there is diffusion in 
certain directions when there is not a 

47
00:03:52.398 --> 00:03:56.000
strong gradient. 
And there is no diffusion or reduced 

48
00:03:56.000 --> 00:04:00.349
diffusion where there is a strong 
gradient, meaning across edges. 

49
00:04:00.349 --> 00:04:03.475
And that's where we get very sharp 
boundaries. 

50
00:04:03.475 --> 00:04:08.368
We preserve them while at the same time, 
regularizing inside the objects. 

51
00:04:08.368 --> 00:04:13.604
And that's what we want. 
These equations are the results of 

52
00:04:13.604 --> 00:04:19.988
Calculus of variations. 
So, if we basically define any function 

53
00:04:19.988 --> 00:04:22.460
of the gradient, 
so here, 

54
00:04:22.460 --> 00:04:31.367
this is what we saw the last time that we 
were basically taking functions of u or 

55
00:04:31.367 --> 00:04:36.340
derivatives of u. 
And basically, the gradient is the 

56
00:04:36.340 --> 00:04:40.939
derivative of the image and rho here 
takes the role of f. 

57
00:04:40.939 --> 00:04:45.522
So, we take any function of the magnitude 
of the gradient. 

58
00:04:45.522 --> 00:04:49.784
If we compute the Euler-Lagrange, this is 
what we get. 

59
00:04:49.784 --> 00:04:55.896
That's the Euler-Lagrange of that 
equation if we follow exactly the formula 

60
00:04:55.896 --> 00:05:01.766
that we show in the previous video. 
And remember, the partial differential 

61
00:05:01.766 --> 00:05:07.556
equation is obtained by deforming the 
image equal to the Euler-Lagrange. 

62
00:05:07.556 --> 00:05:11.581
And then, 
when this doesn't change anymore, we have 

63
00:05:11.581 --> 00:05:17.861
solved the Euler-Lagrange and we have 
obtained may be only local, but at least 

64
00:05:17.861 --> 00:05:21.564
we obtained that minimizer of this 
functional. 

65
00:05:21.564 --> 00:05:27.764
So, once again, this is just by doing the 
Euler-Lagrange that we learned in the 

66
00:05:27.764 --> 00:05:32.353
previous video. 
We just pick a couple of examples of this 

67
00:05:32.353 --> 00:05:41.063
raw function to show how nice this is. 
For example, let us consider rho of a to 

68
00:05:41.063 --> 00:05:47.035
be a squared. 
So here, I am trying to minimize the 

69
00:05:47.035 --> 00:05:53.757
magnitude of the gradient squared. 
And then, the Euler-Lagrange, 

70
00:05:53.757 --> 00:05:58.954
so ir rho of a is a squared, then rho 
prime is 2a, 

71
00:05:58.954 --> 00:06:02.681
okay? 
So, instead of rho prime, I have to put 

72
00:06:02.681 --> 00:06:08.322
two times whatever is inside rho, which 
is the gradient, 

73
00:06:08.322 --> 00:06:12.528
okay? 
So basically, have here, and then the 

74
00:06:12.528 --> 00:06:18.999
Euler-Lagrange that I get is, the 
Euler-Lagrange equation is pie t, 

75
00:06:18.999 --> 00:06:24.739
this is this, equal to divergence of rho 
prime, basically 2a. 

76
00:06:24.739 --> 00:06:31.257
Let me ignore the two, it's just scale. 
So, a time, we mean, replace the 

77
00:06:31.257 --> 00:06:31.257
gradient, 
okay? 

78
00:06:32.619 --> 00:06:40.694
a is taking basically the position of the 
gradient, the absolute magnitude of the 

79
00:06:40.694 --> 00:06:44.294
gradient, sorry. 
And this is this part. 

80
00:06:44.294 --> 00:06:49.147
So, this part stays and this part is rho 
prime. 

81
00:06:49.147 --> 00:06:58.083
Now, these two cancel and I go divergence 
of basically the gradient and this is the 

82
00:06:58.083 --> 00:07:03.785
Laplacian. 
For this function, the Euler-Lagrange is 

83
00:07:03.785 --> 00:07:08.607
basically the heat flow and that's 
isotropic. 

84
00:07:08.607 --> 00:07:14.392
That's basically smoothing it in an 
isotropic fashion, 

85
00:07:14.392 --> 00:07:18.637
okay? 
So, that's the Euler-Lagrange of the 

86
00:07:18.637 --> 00:07:25.019
square of the absolute value of the 
magnitude, we get the regular heat flow, 

87
00:07:25.019 --> 00:07:28.848
the Isotropic Diffusion, diffusion all 
around. 

88
00:07:28.848 --> 00:07:35.060
Let's just pick another example that is 
really, really, really interesting. 

89
00:07:35.060 --> 00:07:44.588
Let's just pick, for example, a function 
that basically, rho of a = a, okay? 

90
00:07:44.588 --> 00:07:52.062
Just itself, we could take the absolute 
value of a but let's just leave that 

91
00:07:52.062 --> 00:07:57.372
technicality aside for a second. 
Then, rho prime is one, 

92
00:07:57.372 --> 00:08:00.814
okay? 
So, I'm basically going to try to 

93
00:08:00.814 --> 00:08:05.664
minimize the absolute value of the 
gradient, 

94
00:08:05.664 --> 00:08:09.705
not the gradient square, 
the absolute value of the gradient 

95
00:08:09.705 --> 00:08:14.020
without putting it to the square. 
And then, what do I get as the 

96
00:08:14.020 --> 00:08:19.498
Euler-Lagrange equation of that? 
So, rho prime is now a constant. 

97
00:08:19.498 --> 00:08:26.071
So, I go, divergence of gradient 
normalized by the gradient. 

98
00:08:26.071 --> 00:08:33.493
So, I didn't get anymore the heat flow. 
I got this normalization factor that is 

99
00:08:33.493 --> 00:08:40.821
saying, wait a second, if the grand is 
very high, you are one over the gradient 

100
00:08:40.821 --> 00:08:45.103
so slow down and try to preserve those 
edges. 

101
00:08:45.103 --> 00:08:49.766
So, this is one example of an Isotropic 
Diffusion. 

102
00:08:49.766 --> 00:08:57.990
It's actually called the total variation. 
Total [SOUND] variation, that's basically 

103
00:08:57.990 --> 00:09:04.634
the name of this equation. 
And now, I want you to think for a 

104
00:09:04.634 --> 00:09:11.258
second, what is this? 
We learned it a couple of videos ago. 

105
00:09:11.258 --> 00:09:16.310
This is curvature of the level lines of 
the image I. 

106
00:09:16.310 --> 00:09:23.648
We actually use it as a genetic function. 
We use it phi, in that case, or, or phi, 

107
00:09:23.648 --> 00:09:28.801
we use this in that case. 
Now, this is the curvature of every level 

108
00:09:28.801 --> 00:09:33.017
line of the image. 
So, we are basically considering the 

109
00:09:33.017 --> 00:09:38.951
image as a surface and we are deforming 
the image, we are doing an Isotropic 

110
00:09:38.951 --> 00:09:45.262
Diffusion of the image in such a way that 
basically it's moving according to the 

111
00:09:45.262 --> 00:09:51.151
curvature of the level lines and that's 
getting us an Isotropic Diffusion. 

112
00:09:51.151 --> 00:09:54.652
This is an extremely interesting 
connection. 

113
00:09:54.652 --> 00:10:00.064
We talked about curve evolution, we 
talked about curvature type of motions. 

114
00:10:00.064 --> 00:10:05.714
This is a curvature type of motion. 
That basically the image is moving based 

115
00:10:05.714 --> 00:10:10.883
on curvature of the level lines and 
that's, we don't really care about the 

116
00:10:10.883 --> 00:10:16.332
level lines or we didn't derive this 
equation from the level lines, we derived 

117
00:10:16.332 --> 00:10:19.825
it from the Euler-Lagrange of the total 
variation. 

118
00:10:19.825 --> 00:10:24.925
But we connected between the both, 
between both of them moving according to 

119
00:10:24.925 --> 00:10:30.444
curvature type of equations and moving 
curvature of the level lines and moving 

120
00:10:30.444 --> 00:10:34.380
according to the Euler-Lagrange. 
The curvature of what? 

121
00:10:34.380 --> 00:10:37.935
The curvature of the level lines of the 
image. 

122
00:10:37.935 --> 00:10:43.885
A very interesting connection between 
curve evolution, level set, and Calculus 

123
00:10:43.885 --> 00:10:49.527
of variation, and that gives us a very, 
very nice equation for Anisotropic 

124
00:10:49.527 --> 00:10:52.784
Diffusion. 
And this basically is one of the most 

125
00:10:52.784 --> 00:10:57.557
famous examples of the use of Calculus of 
variations in image processing. 

126
00:10:57.557 --> 00:11:02.656
What's left in this week is to conclude 
the week in the next video with a bit 

127
00:11:02.656 --> 00:11:06.383
more of active contours, 
one of the main clients of curve 

128
00:11:06.383 --> 00:11:11.417
evolution and Calculus of variations as 
we have discussed in the past and that's 

129
00:11:11.417 --> 00:11:14.948
we're going to see in the next video. 
Thank you very much. 

130
00:11:14.948 --> 00:11:17.433
I'm looking forward to that. 
Thank you. 